{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T08:33:24.966135Z",
     "start_time": "2021-06-29T08:33:24.090498Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "from colorama import Fore, Style\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T08:33:25.788940Z",
     "start_time": "2021-06-29T08:33:25.400981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T08:33:26.993718Z",
     "start_time": "2021-06-29T08:33:26.947841Z"
    }
   },
   "outputs": [],
   "source": [
    "#### FUNCTIONS DECLARATION ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T08:33:27.978091Z",
     "start_time": "2021-06-29T08:33:27.725764Z"
    }
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6,\n",
    "                               kernel_size=5)  # kernel = filter size. #out = number of filters\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # hidden conv layers\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)  # activation function\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # hidden linear layers.\n",
    "        t = t.reshape(-1, 12 * 4 * 4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # output layer\n",
    "        t = self.out(t)\n",
    "\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T08:33:28.642309Z",
     "start_time": "2021-06-29T08:33:28.593443Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels): \n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T08:33:29.814166Z",
     "start_time": "2021-06-29T08:33:29.653606Z"
    }
   },
   "outputs": [],
   "source": [
    "def training(network, dataset, loader, lr, num_epochs, test=None):\n",
    "    optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        for batch in loader:\n",
    "            images, labels = batch\n",
    "\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()  # gradient must be reset every time, otherwise it's added to the previous one\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        accuracy = (total_correct / len(dataset)) * 100\n",
    "        print(f'epoch: {epoch}, loss: {total_loss}, total_correct: {total_correct} / {len(dataset)}, --> {Fore.LIGHTCYAN_EX}Accuracy: {accuracy}{Style.RESET_ALL}')\n",
    "        if test is not None:\n",
    "            for t in test:\n",
    "                print(f\"\\t\\t\\t\\t {Fore.LIGHTGREEN_EX}Testing back... {testing(network, t[0], t[1])}{Style.RESET_ALL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T08:33:30.481388Z",
     "start_time": "2021-06-29T08:33:30.454459Z"
    }
   },
   "outputs": [],
   "source": [
    "def testing(network, dataset, loader):\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            images, labels = batch\n",
    "            predictions = network(images)\n",
    "            correct = get_num_correct(predictions, labels)\n",
    "            total_correct += correct\n",
    "        return (\n",
    "            f'total correct: {total_correct} / {len(dataset)}. {Fore.LIGHTMAGENTA_EX}Accuracy: {(total_correct / len(dataset)) * 100}{Style.RESET_ALL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T08:33:31.752987Z",
     "start_time": "2021-06-29T08:33:31.641287Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_indices(idx):\n",
    "    indices = []\n",
    "    for i in range(len(idx)):\n",
    "        if idx[i].item() == True:\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "\n",
    "def split_dataset(dataset):\n",
    "    subsets = []\n",
    "    for i in range(10):\n",
    "        idx = mnist.targets==i\n",
    "        indices = find_indices(idx)\n",
    "        subset = torch.utils.data.Subset(dataset, indices)\n",
    "        #print('subset:', i, 'len: ', len(subset))\n",
    "        subsets.append(subset)\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T08:56:17.746561Z",
     "start_time": "2021-06-29T08:56:17.694701Z"
    }
   },
   "outputs": [],
   "source": [
    "def example_replay(N, digits, network, memory_dataset, train_dataset, memory_loader, train_loader):\n",
    "    crumbs = []\n",
    "    for digit in digits:\n",
    "        l = len(digit)\n",
    "        indices = random.sample(range(1,l), N)\n",
    "        crumb = torch.utils.data.Subset(digit, indices)\n",
    "        crumbs.append(crumb)\n",
    "    crumbs.append(train_dataset)\n",
    "    dirty_dataset = torch.utils.data.ConcatDataset(crumbs)\n",
    "    dirty_loader = torch.utils.data.DataLoader(dirty_dataset, batch_size=100, shuffle=True)\n",
    "    print(f'Sto rinfrescando la memoria con {N} elementi da mnist per ogni classe. dirty: {len(dirty_dataset)}')\n",
    "    training(network, dirty_dataset, dirty_loader, lr=1e-3, num_epochs=10)\n",
    "    print(f'Results for mnist: {testing(network, mnist, mnist_loader)}') \n",
    "    print(f'Results for usps: {testing(network, usps, usps_loader)}')\n",
    "    print(f'Results for svhn: {testing(network, svhn, svhn_loader)}')\n",
    "    print('    ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T08:33:35.311482Z",
     "start_time": "2021-06-29T08:33:35.295509Z"
    }
   },
   "outputs": [],
   "source": [
    "#### DATASETS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T08:33:36.403543Z",
     "start_time": "2021-06-29T08:33:36.301815Z"
    }
   },
   "outputs": [],
   "source": [
    "USPS_transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "SVHN_transform = transforms.Compose([transforms.Resize((28, 28)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Grayscale(num_output_channels=1) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T08:34:01.319890Z",
     "start_time": "2021-06-29T08:33:37.456727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data\\train_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "mnist = torchvision.datasets.MNIST(\n",
    "                        root='./data'\n",
    "                       ,train=True\n",
    "                       ,download=True\n",
    "                       ,transform = transforms.Compose([transforms.ToTensor()])\n",
    "                        )\n",
    "\n",
    "usps = torchvision.datasets.USPS(\"./data\"\n",
    "                     , train=True\n",
    "                     , download=True\n",
    "                     , transform = USPS_transform\n",
    "                    )\n",
    "\n",
    "svhn = torchvision.datasets.SVHN(root='./data' ,\n",
    "                                 split='train' ,\n",
    "                                 transform=SVHN_transform,\n",
    "                                 download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T08:34:01.573214Z",
     "start_time": "2021-06-29T08:34:01.332864Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_loader = torch.utils.data.DataLoader(mnist, batch_size = 100, shuffle=True)\n",
    "usps_loader = torch.utils.data.DataLoader(usps, batch_size = 100, shuffle=True)\n",
    "svhn_loader = torch.utils.data.DataLoader(svhn, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T17:59:01.330660Z",
     "start_time": "2021-06-28T17:59:01.306661Z"
    }
   },
   "outputs": [],
   "source": [
    "######## CREIAMO IL NOSTRO NETWORK #####\n",
    "\n",
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T18:03:26.825402Z",
     "start_time": "2021-06-28T17:59:01.330660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 121.96751784067601, total_correct: 56114 / 60000, --> \u001b[96mAccuracy: 93.52333333333334\u001b[0m\n",
      "epoch: 1, loss: 46.97961293812841, total_correct: 58612 / 60000, --> \u001b[96mAccuracy: 97.68666666666667\u001b[0m\n",
      "epoch: 2, loss: 39.94442648696713, total_correct: 58832 / 60000, --> \u001b[96mAccuracy: 98.05333333333334\u001b[0m\n",
      "epoch: 3, loss: 38.81191668700194, total_correct: 58916 / 60000, --> \u001b[96mAccuracy: 98.19333333333333\u001b[0m\n",
      "epoch: 4, loss: 35.137164528656285, total_correct: 59031 / 60000, --> \u001b[96mAccuracy: 98.385\u001b[0m\n",
      "epoch: 5, loss: 35.94039195960795, total_correct: 59064 / 60000, --> \u001b[96mAccuracy: 98.44000000000001\u001b[0m\n",
      "epoch: 6, loss: 34.47021762432996, total_correct: 59099 / 60000, --> \u001b[96mAccuracy: 98.49833333333333\u001b[0m\n",
      "epoch: 7, loss: 35.01557728933403, total_correct: 59065 / 60000, --> \u001b[96mAccuracy: 98.44166666666668\u001b[0m\n",
      "epoch: 8, loss: 34.733114582893904, total_correct: 59128 / 60000, --> \u001b[96mAccuracy: 98.54666666666667\u001b[0m\n",
      "epoch: 9, loss: 34.38552636926761, total_correct: 59196 / 60000, --> \u001b[96mAccuracy: 98.66\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "######## FACCIAMO IL TRAINING SU MNIST #######\n",
    "\n",
    "training(network, mnist, mnist_loader, lr=0.01, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T18:03:26.841403Z",
     "start_time": "2021-06-28T18:03:26.825402Z"
    }
   },
   "outputs": [],
   "source": [
    "#### SALVIAMO QUESTA RETE #####\n",
    "\n",
    "torch.save(network.state_dict(), 'PATHS/mnist_trained.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T18:03:44.659807Z",
     "start_time": "2021-06-28T18:03:26.841403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist:  total correct: 59264 / 60000. \u001b[95mAccuracy: 98.77333333333334\u001b[0m\n",
      "usps:  total correct: 3180 / 7291. \u001b[95mAccuracy: 43.61541626663009\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#### FACCIAMO IL TEST SU MNIST/USPS/FASHION\n",
    "\n",
    "print('mnist: ', (testing(network, mnist, mnist_loader)))\n",
    "print('usps: ', (testing(network, usps, usps_loader))) #forward training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T18:04:19.209135Z",
     "start_time": "2021-06-28T18:03:44.659807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 55.63860809803009, total_correct: 5629 / 7291, --> \u001b[96mAccuracy: 77.20477300781786\u001b[0m\n",
      "epoch: 1, loss: 20.49654772132635, total_correct: 6716 / 7291, --> \u001b[96mAccuracy: 92.11356466876973\u001b[0m\n",
      "epoch: 2, loss: 14.65783029422164, total_correct: 6882 / 7291, --> \u001b[96mAccuracy: 94.39034426004663\u001b[0m\n",
      "epoch: 3, loss: 11.495309740304947, total_correct: 6970 / 7291, --> \u001b[96mAccuracy: 95.59731175421753\u001b[0m\n",
      "epoch: 4, loss: 9.48992214165628, total_correct: 7010 / 7291, --> \u001b[96mAccuracy: 96.14593334247704\u001b[0m\n",
      "epoch: 5, loss: 7.984057238325477, total_correct: 7052 / 7291, --> \u001b[96mAccuracy: 96.7219860101495\u001b[0m\n",
      "epoch: 6, loss: 6.71717047598213, total_correct: 7097 / 7291, --> \u001b[96mAccuracy: 97.33918529694144\u001b[0m\n",
      "epoch: 7, loss: 5.713647751137614, total_correct: 7129 / 7291, --> \u001b[96mAccuracy: 97.77808256754903\u001b[0m\n",
      "epoch: 8, loss: 4.912942534312606, total_correct: 7153 / 7291, --> \u001b[96mAccuracy: 98.10725552050474\u001b[0m\n",
      "epoch: 9, loss: 4.240828321315348, total_correct: 7171 / 7291, --> \u001b[96mAccuracy: 98.3541352352215\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#### FACCIAMO IL FINE-TUNING SU USPS SENZA MEMORIA ###\n",
    "\n",
    "training(network, usps, usps_loader, lr=1e-3, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T18:04:37.102306Z",
     "start_time": "2021-06-28T18:04:19.209135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist:  total correct: 55870 / 60000. \u001b[95mAccuracy: 93.11666666666667\u001b[0m\n",
      "usps:  total correct: 7191 / 7291. \u001b[95mAccuracy: 98.62844602935125\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### FACCIAMO IL TEST SU MNIST/USPS ###\n",
    "print('mnist: ', (testing(network, mnist, mnist_loader))) #forgetting\n",
    "print('usps: ', (testing(network, usps, usps_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T18:16:56.325194Z",
     "start_time": "2021-06-28T18:04:37.102306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sto rinfrescando la memoria con 1 elementi da mnist per ogni classe. dirty: 7301\n",
      "epoch: 0, loss: 55.07654559612274, total_correct: 5689 / 7301, --> \u001b[96mAccuracy: 77.92083276263526\u001b[0m\n",
      "epoch: 1, loss: 20.639145158228985, total_correct: 6718 / 7301, --> \u001b[96mAccuracy: 92.01479249417888\u001b[0m\n",
      "epoch: 2, loss: 14.579185705620148, total_correct: 6905 / 7301, --> \u001b[96mAccuracy: 94.57608546774414\u001b[0m\n",
      "epoch: 3, loss: 11.440479651093483, total_correct: 6973 / 7301, --> \u001b[96mAccuracy: 95.50746473085879\u001b[0m\n",
      "epoch: 4, loss: 9.402980236336582, total_correct: 7025 / 7301, --> \u001b[96mAccuracy: 96.2196959320641\u001b[0m\n",
      "epoch: 5, loss: 7.881992489099503, total_correct: 7069 / 7301, --> \u001b[96mAccuracy: 96.82235310231475\u001b[0m\n",
      "epoch: 6, loss: 6.535078125074506, total_correct: 7105 / 7301, --> \u001b[96mAccuracy: 97.31543624161074\u001b[0m\n",
      "epoch: 7, loss: 5.4815196506640405, total_correct: 7138 / 7301, --> \u001b[96mAccuracy: 97.76742911929873\u001b[0m\n",
      "epoch: 8, loss: 4.730538428528234, total_correct: 7163 / 7301, --> \u001b[96mAccuracy: 98.10984796603205\u001b[0m\n",
      "epoch: 9, loss: 4.02587226605101, total_correct: 7189 / 7301, --> \u001b[96mAccuracy: 98.46596356663471\u001b[0m\n",
      "Results for mnist: total correct: 55742 / 60000. \u001b[95mAccuracy: 92.90333333333334\u001b[0m\n",
      "Results for usps: total correct: 7196 / 7291. \u001b[95mAccuracy: 98.69702372788369\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 2 elementi da mnist per ogni classe. dirty: 7311\n",
      "epoch: 0, loss: 53.16169245541096, total_correct: 5727 / 7311, --> \u001b[96mAccuracy: 78.33401723430448\u001b[0m\n",
      "epoch: 1, loss: 20.524527303874493, total_correct: 6753 / 7311, --> \u001b[96mAccuracy: 92.36766516208453\u001b[0m\n",
      "epoch: 2, loss: 14.600570660084486, total_correct: 6909 / 7311, --> \u001b[96mAccuracy: 94.50143619203939\u001b[0m\n",
      "epoch: 3, loss: 11.747391883283854, total_correct: 6981 / 7311, --> \u001b[96mAccuracy: 95.4862535904801\u001b[0m\n",
      "epoch: 4, loss: 9.648810341954231, total_correct: 7041 / 7311, --> \u001b[96mAccuracy: 96.30693475584735\u001b[0m\n",
      "epoch: 5, loss: 8.197631161659956, total_correct: 7074 / 7311, --> \u001b[96mAccuracy: 96.75830939679935\u001b[0m\n",
      "epoch: 6, loss: 6.7756974045187235, total_correct: 7118 / 7311, --> \u001b[96mAccuracy: 97.360142251402\u001b[0m\n",
      "epoch: 7, loss: 5.82574074761942, total_correct: 7132 / 7311, --> \u001b[96mAccuracy: 97.55163452332101\u001b[0m\n",
      "epoch: 8, loss: 5.145795241929591, total_correct: 7162 / 7311, --> \u001b[96mAccuracy: 97.96197510600464\u001b[0m\n",
      "epoch: 9, loss: 4.6070370762608945, total_correct: 7180 / 7311, --> \u001b[96mAccuracy: 98.20817945561483\u001b[0m\n",
      "Results for mnist: total correct: 56242 / 60000. \u001b[95mAccuracy: 93.73666666666666\u001b[0m\n",
      "Results for usps: total correct: 7179 / 7291. \u001b[95mAccuracy: 98.4638595528734\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 5 elementi da mnist per ogni classe. dirty: 7341\n",
      "epoch: 0, loss: 54.13570572435856, total_correct: 5722 / 7341, --> \u001b[96mAccuracy: 77.94578395313991\u001b[0m\n",
      "epoch: 1, loss: 20.600632458925247, total_correct: 6779 / 7341, --> \u001b[96mAccuracy: 92.34436725241792\u001b[0m\n",
      "epoch: 2, loss: 14.685469307005405, total_correct: 6928 / 7341, --> \u001b[96mAccuracy: 94.37406347909004\u001b[0m\n",
      "epoch: 3, loss: 11.589366000145674, total_correct: 7023 / 7341, --> \u001b[96mAccuracy: 95.66816510012261\u001b[0m\n",
      "epoch: 4, loss: 9.371065396815538, total_correct: 7062 / 7341, --> \u001b[96mAccuracy: 96.19942787086228\u001b[0m\n",
      "epoch: 5, loss: 7.722997419536114, total_correct: 7118 / 7341, --> \u001b[96mAccuracy: 96.96226672115516\u001b[0m\n",
      "epoch: 6, loss: 6.478341843932867, total_correct: 7154 / 7341, --> \u001b[96mAccuracy: 97.45266312491486\u001b[0m\n",
      "epoch: 7, loss: 5.580504206009209, total_correct: 7178 / 7341, --> \u001b[96mAccuracy: 97.77959406075468\u001b[0m\n",
      "epoch: 8, loss: 4.73400157969445, total_correct: 7205 / 7341, --> \u001b[96mAccuracy: 98.14739136357444\u001b[0m\n",
      "epoch: 9, loss: 3.96879800921306, total_correct: 7229 / 7341, --> \u001b[96mAccuracy: 98.47432229941425\u001b[0m\n",
      "Results for mnist: total correct: 57092 / 60000. \u001b[95mAccuracy: 95.15333333333334\u001b[0m\n",
      "Results for usps: total correct: 7189 / 7291. \u001b[95mAccuracy: 98.60101494993827\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 10 elementi da mnist per ogni classe. dirty: 7391\n",
      "epoch: 0, loss: 54.87756736576557, total_correct: 5776 / 7391, --> \u001b[96mAccuracy: 78.1491002570694\u001b[0m\n",
      "epoch: 1, loss: 20.749639958143234, total_correct: 6819 / 7391, --> \u001b[96mAccuracy: 92.26085780002707\u001b[0m\n",
      "epoch: 2, loss: 14.579943180084229, total_correct: 6990 / 7391, --> \u001b[96mAccuracy: 94.5744824786903\u001b[0m\n",
      "epoch: 3, loss: 11.599512297660112, total_correct: 7061 / 7391, --> \u001b[96mAccuracy: 95.53511026924639\u001b[0m\n",
      "epoch: 4, loss: 9.435513131320477, total_correct: 7122 / 7391, --> \u001b[96mAccuracy: 96.36043837099176\u001b[0m\n",
      "epoch: 5, loss: 7.860410742461681, total_correct: 7163 / 7391, --> \u001b[96mAccuracy: 96.91516709511568\u001b[0m\n",
      "epoch: 6, loss: 6.547698359005153, total_correct: 7201 / 7391, --> \u001b[96mAccuracy: 97.42930591259639\u001b[0m\n",
      "epoch: 7, loss: 5.579834974370897, total_correct: 7231 / 7391, --> \u001b[96mAccuracy: 97.83520497902855\u001b[0m\n",
      "epoch: 8, loss: 4.798480827827007, total_correct: 7254 / 7391, --> \u001b[96mAccuracy: 98.14639426329319\u001b[0m\n",
      "epoch: 9, loss: 4.069830488413572, total_correct: 7269 / 7391, --> \u001b[96mAccuracy: 98.34934379650927\u001b[0m\n",
      "Results for mnist: total correct: 57402 / 60000. \u001b[95mAccuracy: 95.67\u001b[0m\n",
      "Results for usps: total correct: 7187 / 7291. \u001b[95mAccuracy: 98.57358387052531\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 50 elementi da mnist per ogni classe. dirty: 7791\n",
      "epoch: 0, loss: 54.801568537950516, total_correct: 6146 / 7791, --> \u001b[96mAccuracy: 78.8858939802336\u001b[0m\n",
      "epoch: 1, loss: 20.75496682524681, total_correct: 7215 / 7791, --> \u001b[96mAccuracy: 92.60685406237967\u001b[0m\n",
      "epoch: 2, loss: 14.84685803949833, total_correct: 7387 / 7791, --> \u001b[96mAccuracy: 94.81452958541907\u001b[0m\n",
      "epoch: 3, loss: 11.616512078791857, total_correct: 7460 / 7791, --> \u001b[96mAccuracy: 95.75150815042998\u001b[0m\n",
      "epoch: 4, loss: 9.45530553162098, total_correct: 7506 / 7791, --> \u001b[96mAccuracy: 96.34193299961494\u001b[0m\n",
      "epoch: 5, loss: 7.793890507891774, total_correct: 7564 / 7791, --> \u001b[96mAccuracy: 97.08638172250032\u001b[0m\n",
      "epoch: 6, loss: 6.473080160096288, total_correct: 7606 / 7791, --> \u001b[96mAccuracy: 97.6254652804518\u001b[0m\n",
      "epoch: 7, loss: 5.383759398944676, total_correct: 7640 / 7791, --> \u001b[96mAccuracy: 98.06186625593634\u001b[0m\n",
      "epoch: 8, loss: 4.5732415749225765, total_correct: 7664 / 7791, --> \u001b[96mAccuracy: 98.36991400333719\u001b[0m\n",
      "epoch: 9, loss: 3.9542912198230624, total_correct: 7675 / 7791, --> \u001b[96mAccuracy: 98.51110255422924\u001b[0m\n",
      "Results for mnist: total correct: 58204 / 60000. \u001b[95mAccuracy: 97.00666666666666\u001b[0m\n",
      "Results for usps: total correct: 7186 / 7291. \u001b[95mAccuracy: 98.55986833081883\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 100 elementi da mnist per ogni classe. dirty: 8291\n",
      "epoch: 0, loss: 52.989113450050354, total_correct: 6682 / 8291, --> \u001b[96mAccuracy: 80.59341454589314\u001b[0m\n",
      "epoch: 1, loss: 20.395992413163185, total_correct: 7728 / 8291, --> \u001b[96mAccuracy: 93.2095042817513\u001b[0m\n",
      "epoch: 2, loss: 14.640226285904646, total_correct: 7878 / 8291, --> \u001b[96mAccuracy: 95.01869497044989\u001b[0m\n",
      "epoch: 3, loss: 11.47116744890809, total_correct: 7967 / 8291, --> \u001b[96mAccuracy: 96.09214811241105\u001b[0m\n",
      "epoch: 4, loss: 9.255956383422017, total_correct: 8031 / 8291, --> \u001b[96mAccuracy: 96.86406947292244\u001b[0m\n",
      "epoch: 5, loss: 7.461046900600195, total_correct: 8074 / 8291, --> \u001b[96mAccuracy: 97.38270413701603\u001b[0m\n",
      "epoch: 6, loss: 6.200772235170007, total_correct: 8111 / 8291, --> \u001b[96mAccuracy: 97.8289711735617\u001b[0m\n",
      "epoch: 7, loss: 5.238780688960105, total_correct: 8138 / 8291, --> \u001b[96mAccuracy: 98.15462549752743\u001b[0m\n",
      "epoch: 8, loss: 4.407014444004744, total_correct: 8161 / 8291, --> \u001b[96mAccuracy: 98.43203473646123\u001b[0m\n",
      "epoch: 9, loss: 3.8220919757150114, total_correct: 8175 / 8291, --> \u001b[96mAccuracy: 98.6008925340731\u001b[0m\n",
      "Results for mnist: total correct: 58625 / 60000. \u001b[95mAccuracy: 97.70833333333333\u001b[0m\n",
      "Results for usps: total correct: 7204 / 7291. \u001b[95mAccuracy: 98.8067480455356\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 500 elementi da mnist per ogni classe. dirty: 12291\n",
      "epoch: 0, loss: 48.303620748221874, total_correct: 10864 / 12291, --> \u001b[96mAccuracy: 88.389878773086\u001b[0m\n",
      "epoch: 1, loss: 20.62721174582839, total_correct: 11715 / 12291, --> \u001b[96mAccuracy: 95.31364412985111\u001b[0m\n",
      "epoch: 2, loss: 14.759771707933396, total_correct: 11861 / 12291, --> \u001b[96mAccuracy: 96.5015051663819\u001b[0m\n",
      "epoch: 3, loss: 11.274085151962936, total_correct: 11973 / 12291, --> \u001b[96mAccuracy: 97.41274103002196\u001b[0m\n",
      "epoch: 4, loss: 8.857870841398835, total_correct: 12028 / 12291, --> \u001b[96mAccuracy: 97.8602229273452\u001b[0m\n",
      "epoch: 5, loss: 7.169139877427369, total_correct: 12071 / 12291, --> \u001b[96mAccuracy: 98.21007241070701\u001b[0m\n",
      "epoch: 6, loss: 5.8547200369648635, total_correct: 12123 / 12291, --> \u001b[96mAccuracy: 98.63314620453991\u001b[0m\n",
      "epoch: 7, loss: 4.91372412268538, total_correct: 12147 / 12291, --> \u001b[96mAccuracy: 98.82841103246278\u001b[0m\n",
      "epoch: 8, loss: 4.216081086546183, total_correct: 12169 / 12291, --> \u001b[96mAccuracy: 99.00740379139208\u001b[0m\n",
      "epoch: 9, loss: 3.6138157764216885, total_correct: 12178 / 12291, --> \u001b[96mAccuracy: 99.08062810186316\u001b[0m\n",
      "Results for mnist: total correct: 59290 / 60000. \u001b[95mAccuracy: 98.81666666666666\u001b[0m\n",
      "Results for usps: total correct: 7206 / 7291. \u001b[95mAccuracy: 98.83417912494856\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 1000 elementi da mnist per ogni classe. dirty: 17291\n",
      "epoch: 0, loss: 46.63905135542154, total_correct: 15971 / 17291, --> \u001b[96mAccuracy: 92.36597073622116\u001b[0m\n",
      "epoch: 1, loss: 21.282475462183356, total_correct: 16694 / 17291, --> \u001b[96mAccuracy: 96.54733676479094\u001b[0m\n",
      "epoch: 2, loss: 15.368743075057864, total_correct: 16863 / 17291, --> \u001b[96mAccuracy: 97.52472384477474\u001b[0m\n",
      "epoch: 3, loss: 11.776224181521684, total_correct: 16972 / 17291, --> \u001b[96mAccuracy: 98.15510959458678\u001b[0m\n",
      "epoch: 4, loss: 9.304831084329635, total_correct: 17021 / 17291, --> \u001b[96mAccuracy: 98.43849401422705\u001b[0m\n",
      "epoch: 5, loss: 7.67082948749885, total_correct: 17068 / 17291, --> \u001b[96mAccuracy: 98.7103117228616\u001b[0m\n",
      "epoch: 6, loss: 6.292188652441837, total_correct: 17100 / 17291, --> \u001b[96mAccuracy: 98.89537909895321\u001b[0m\n",
      "epoch: 7, loss: 5.26972840889357, total_correct: 17140 / 17291, --> \u001b[96mAccuracy: 99.12671331906773\u001b[0m\n",
      "epoch: 8, loss: 4.368996123695979, total_correct: 17164 / 17291, --> \u001b[96mAccuracy: 99.26551385113643\u001b[0m\n",
      "epoch: 9, loss: 3.742314563540276, total_correct: 17181 / 17291, --> \u001b[96mAccuracy: 99.3638308946851\u001b[0m\n",
      "Results for mnist: total correct: 59502 / 60000. \u001b[95mAccuracy: 99.17\u001b[0m\n",
      "Results for usps: total correct: 7211 / 7291. \u001b[95mAccuracy: 98.90275682348101\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 2000 elementi da mnist per ogni classe. dirty: 27291\n",
      "epoch: 0, loss: 42.94985391758382, total_correct: 26033 / 27291, --> \u001b[96mAccuracy: 95.39042175076032\u001b[0m\n",
      "epoch: 1, loss: 20.90835762792267, total_correct: 26703 / 27291, --> \u001b[96mAccuracy: 97.84544355281962\u001b[0m\n",
      "epoch: 2, loss: 14.910984244430438, total_correct: 26880 / 27291, --> \u001b[96mAccuracy: 98.49400901396065\u001b[0m\n",
      "epoch: 3, loss: 11.623159822192974, total_correct: 26957 / 27291, --> \u001b[96mAccuracy: 98.77615331061523\u001b[0m\n",
      "epoch: 4, loss: 9.300398014194798, total_correct: 27022 / 27291, --> \u001b[96mAccuracy: 99.01432706753141\u001b[0m\n",
      "epoch: 5, loss: 7.501291755528655, total_correct: 27077 / 27291, --> \u001b[96mAccuracy: 99.21585870799898\u001b[0m\n",
      "epoch: 6, loss: 6.083317124575842, total_correct: 27111 / 27291, --> \u001b[96mAccuracy: 99.34044190392437\u001b[0m\n",
      "epoch: 7, loss: 5.147889689629665, total_correct: 27138 / 27291, --> \u001b[96mAccuracy: 99.43937561833572\u001b[0m\n",
      "epoch: 8, loss: 4.216113297414267, total_correct: 27154 / 27291, --> \u001b[96mAccuracy: 99.49800300465354\u001b[0m\n",
      "epoch: 9, loss: 3.6257673412328586, total_correct: 27180 / 27291, --> \u001b[96mAccuracy: 99.59327250742002\u001b[0m\n",
      "Results for mnist: total correct: 59671 / 60000. \u001b[95mAccuracy: 99.45166666666667\u001b[0m\n",
      "Results for usps: total correct: 7216 / 7291. \u001b[95mAccuracy: 98.97133452201345\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 5000 elementi da mnist per ogni classe. dirty: 57291\n",
      "epoch: 0, loss: 46.596480874868575, total_correct: 55982 / 57291, --> \u001b[96mAccuracy: 97.71517341292699\u001b[0m\n",
      "epoch: 1, loss: 23.49521275580628, total_correct: 56640 / 57291, --> \u001b[96mAccuracy: 98.86369586846101\u001b[0m\n",
      "epoch: 2, loss: 17.24977685615886, total_correct: 56783 / 57291, --> \u001b[96mAccuracy: 99.11329877293117\u001b[0m\n",
      "epoch: 3, loss: 13.140958500596753, total_correct: 56900 / 57291, --> \u001b[96mAccuracy: 99.31751933113404\u001b[0m\n",
      "epoch: 4, loss: 10.47240388521459, total_correct: 56982 / 57291, --> \u001b[96mAccuracy: 99.46064826936168\u001b[0m\n",
      "epoch: 5, loss: 9.13956459855035, total_correct: 57006 / 57291, --> \u001b[96mAccuracy: 99.50253966591612\u001b[0m\n",
      "epoch: 6, loss: 7.409717468355666, total_correct: 57064 / 57291, --> \u001b[96mAccuracy: 99.60377720758933\u001b[0m\n",
      "epoch: 7, loss: 5.985081815280864, total_correct: 57111 / 57291, --> \u001b[96mAccuracy: 99.68581452584175\u001b[0m\n",
      "epoch: 8, loss: 5.221184358813844, total_correct: 57128 / 57291, --> \u001b[96mAccuracy: 99.71548759840114\u001b[0m\n",
      "epoch: 9, loss: 4.263190926842981, total_correct: 57161 / 57291, --> \u001b[96mAccuracy: 99.77308826866349\u001b[0m\n",
      "Results for mnist: total correct: 59906 / 60000. \u001b[95mAccuracy: 99.84333333333333\u001b[0m\n",
      "Results for usps: total correct: 7221 / 7291. \u001b[95mAccuracy: 99.03991222054587\u001b[0m\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "### RIPRENDIAMO LA RETE MEMORIZZATA AL SOLO MNIST TRAINED E PROVIAMO A FARE IL TRAINING SU USPS CON MEMORIA DI MNIST ###\n",
    "### il nostro obiettivo sarà quello di migliorare l'accuratezza del mnist dell' 85% ###\n",
    "digits = split_dataset(mnist)\n",
    "network_mnist = Network()\n",
    "for N in (1,2,5,10,50,100,500,1000,2000,5000):\n",
    "    network_mnist.load_state_dict(torch.load('PATHS/mnist_trained.pth'))\n",
    "    example_replay(N, network_mnist, mnist, usps, mnist_loader, usps_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EXAMPLE REPLAY SU 3 TASK ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T15:06:07.638760Z",
     "start_time": "2021-06-29T15:06:06.474833Z"
    }
   },
   "outputs": [],
   "source": [
    "network2 = Network()\n",
    "combination = []\n",
    "combination.append(mnist)\n",
    "combination.append(usps)\n",
    "joint = torch.utils.data.ConcatDataset(combination)\n",
    "joint_loader = torch.utils.data.DataLoader(joint, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T15:11:15.614614Z",
     "start_time": "2021-06-29T15:06:07.659663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 132.13256027456373, total_correct: 63147 / 67291, --> \u001b[96mAccuracy: 93.84167273483824\u001b[0m\n",
      "epoch: 1, loss: 58.16816308256239, total_correct: 65603 / 67291, --> \u001b[96mAccuracy: 97.49149217577387\u001b[0m\n",
      "epoch: 2, loss: 55.49535472341813, total_correct: 65774 / 67291, --> \u001b[96mAccuracy: 97.74561234043185\u001b[0m\n",
      "epoch: 3, loss: 46.918476193910465, total_correct: 66027 / 67291, --> \u001b[96mAccuracy: 98.12159129749892\u001b[0m\n",
      "epoch: 4, loss: 48.134905279031955, total_correct: 65987 / 67291, --> \u001b[96mAccuracy: 98.06214798412863\u001b[0m\n",
      "epoch: 5, loss: 46.86761846009176, total_correct: 66041 / 67291, --> \u001b[96mAccuracy: 98.14239645717852\u001b[0m\n",
      "epoch: 6, loss: 41.7804994264734, total_correct: 66188 / 67291, --> \u001b[96mAccuracy: 98.36085063381434\u001b[0m\n",
      "epoch: 7, loss: 43.846964185882825, total_correct: 66132 / 67291, --> \u001b[96mAccuracy: 98.27762999509592\u001b[0m\n",
      "epoch: 8, loss: 47.02036430872977, total_correct: 66113 / 67291, --> \u001b[96mAccuracy: 98.24939442124504\u001b[0m\n",
      "epoch: 9, loss: 40.95900429273024, total_correct: 66264 / 67291, --> \u001b[96mAccuracy: 98.47379292921788\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#### TRAINING SU MNIST E USPS INSIEME ####\n",
    "training(network2, joint, joint_loader, lr=0.01, num_epochs=10)\n",
    "torch.save(network2.state_dict(), 'PATHS/combined_mnist+usps.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T16:37:58.870142Z",
     "start_time": "2021-06-29T15:11:15.624587Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sto rinfrescando la memoria con 1 elementi da mnist per ogni classe. dirty: 73267\n",
      "epoch: 0, loss: 1326.5553991794586, total_correct: 28482 / 73267, --> \u001b[96mAccuracy: 38.87425443924277\u001b[0m\n",
      "epoch: 1, loss: 804.1493139266968, total_correct: 47763 / 73267, --> \u001b[96mAccuracy: 65.19033125417991\u001b[0m\n",
      "epoch: 2, loss: 628.4870836734772, total_correct: 53784 / 73267, --> \u001b[96mAccuracy: 73.40821925286964\u001b[0m\n",
      "epoch: 3, loss: 545.6923441588879, total_correct: 56426 / 73267, --> \u001b[96mAccuracy: 77.01420830660462\u001b[0m\n",
      "epoch: 4, loss: 493.09509029984474, total_correct: 58012 / 73267, --> \u001b[96mAccuracy: 79.17889363560676\u001b[0m\n",
      "epoch: 5, loss: 457.678987711668, total_correct: 59053 / 73267, --> \u001b[96mAccuracy: 80.5997242960678\u001b[0m\n",
      "epoch: 6, loss: 432.8102174401283, total_correct: 59856 / 73267, --> \u001b[96mAccuracy: 81.69571567008339\u001b[0m\n",
      "epoch: 7, loss: 412.7911439239979, total_correct: 60450 / 73267, --> \u001b[96mAccuracy: 82.50644901524561\u001b[0m\n",
      "epoch: 8, loss: 396.05594316124916, total_correct: 60986 / 73267, --> \u001b[96mAccuracy: 83.23801984522363\u001b[0m\n",
      "epoch: 9, loss: 382.22987830638885, total_correct: 61419 / 73267, --> \u001b[96mAccuracy: 83.82900896720216\u001b[0m\n",
      "Results for mnist: total correct: 47531 / 60000. \u001b[95mAccuracy: 79.21833333333333\u001b[0m\n",
      "Results for usps: total correct: 4457 / 7291. \u001b[95mAccuracy: 61.13016047181456\u001b[0m\n",
      "Results for svhn: total correct: 61889 / 73257. \u001b[95mAccuracy: 84.48202902111743\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 2 elementi da mnist per ogni classe. dirty: 73277\n",
      "epoch: 0, loss: 1309.8895047307014, total_correct: 28998 / 73277, --> \u001b[96mAccuracy: 39.57312662909235\u001b[0m\n",
      "epoch: 1, loss: 752.7960833311081, total_correct: 49608 / 73277, --> \u001b[96mAccuracy: 67.69927808179919\u001b[0m\n",
      "epoch: 2, loss: 568.7594692111015, total_correct: 55843 / 73277, --> \u001b[96mAccuracy: 76.20808712147058\u001b[0m\n",
      "epoch: 3, loss: 488.56941398978233, total_correct: 58396 / 73277, --> \u001b[96mAccuracy: 79.69212713402568\u001b[0m\n",
      "epoch: 4, loss: 442.0853637754917, total_correct: 59818 / 73277, --> \u001b[96mAccuracy: 81.63270876264039\u001b[0m\n",
      "epoch: 5, loss: 410.2602291405201, total_correct: 60698 / 73277, --> \u001b[96mAccuracy: 82.83363128949055\u001b[0m\n",
      "epoch: 6, loss: 387.5650221258402, total_correct: 61340 / 73277, --> \u001b[96mAccuracy: 83.70975886021535\u001b[0m\n",
      "epoch: 7, loss: 370.78341184556484, total_correct: 61905 / 73277, --> \u001b[96mAccuracy: 84.48080570984075\u001b[0m\n",
      "epoch: 8, loss: 354.67765751481056, total_correct: 62359 / 73277, --> \u001b[96mAccuracy: 85.10037255892026\u001b[0m\n",
      "epoch: 9, loss: 341.96160116791725, total_correct: 62758 / 73277, --> \u001b[96mAccuracy: 85.64488175007165\u001b[0m\n",
      "Results for mnist: total correct: 48659 / 60000. \u001b[95mAccuracy: 81.09833333333333\u001b[0m\n",
      "Results for usps: total correct: 4920 / 7291. \u001b[95mAccuracy: 67.48045535591825\u001b[0m\n",
      "Results for svhn: total correct: 63049 / 73257. \u001b[95mAccuracy: 86.06549544753402\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 5 elementi da mnist per ogni classe. dirty: 73307\n",
      "epoch: 0, loss: 1329.0270644426346, total_correct: 28269 / 73307, --> \u001b[96mAccuracy: 38.56248380100127\u001b[0m\n",
      "epoch: 1, loss: 781.086976647377, total_correct: 48583 / 73307, --> \u001b[96mAccuracy: 66.27334360975078\u001b[0m\n",
      "epoch: 2, loss: 607.7607792317867, total_correct: 54474 / 73307, --> \u001b[96mAccuracy: 74.3094111067156\u001b[0m\n",
      "epoch: 3, loss: 524.0926473736763, total_correct: 57200 / 73307, --> \u001b[96mAccuracy: 78.02801915233198\u001b[0m\n",
      "epoch: 4, loss: 469.95668855309486, total_correct: 58892 / 73307, --> \u001b[96mAccuracy: 80.33612069788697\u001b[0m\n",
      "epoch: 5, loss: 432.48596385121346, total_correct: 60061 / 73307, --> \u001b[96mAccuracy: 81.93078423615752\u001b[0m\n",
      "epoch: 6, loss: 407.56050327420235, total_correct: 60788 / 73307, --> \u001b[96mAccuracy: 82.92250399006916\u001b[0m\n",
      "epoch: 7, loss: 387.71292874217033, total_correct: 61467 / 73307, --> \u001b[96mAccuracy: 83.84874568595086\u001b[0m\n",
      "epoch: 8, loss: 370.8306817561388, total_correct: 62000 / 73307, --> \u001b[96mAccuracy: 84.57582495532486\u001b[0m\n",
      "epoch: 9, loss: 358.0210673213005, total_correct: 62381 / 73307, --> \u001b[96mAccuracy: 85.09555704093744\u001b[0m\n",
      "Results for mnist: total correct: 49763 / 60000. \u001b[95mAccuracy: 82.93833333333333\u001b[0m\n",
      "Results for usps: total correct: 4814 / 7291. \u001b[95mAccuracy: 66.02660814703059\u001b[0m\n",
      "Results for svhn: total correct: 62426 / 73257. \u001b[95mAccuracy: 85.21506477196719\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 10 elementi da mnist per ogni classe. dirty: 73357\n",
      "epoch: 0, loss: 1374.6096140146255, total_correct: 26191 / 73357, --> \u001b[96mAccuracy: 35.703477514075004\u001b[0m\n",
      "epoch: 1, loss: 855.1002388596535, total_correct: 45898 / 73357, --> \u001b[96mAccuracy: 62.56798942159576\u001b[0m\n",
      "epoch: 2, loss: 653.2547416388988, total_correct: 52975 / 73357, --> \u001b[96mAccuracy: 72.21533050697275\u001b[0m\n",
      "epoch: 3, loss: 559.9374549388885, total_correct: 55986 / 73357, --> \u001b[96mAccuracy: 76.31991493654321\u001b[0m\n",
      "epoch: 4, loss: 506.07002079486847, total_correct: 57732 / 73357, --> \u001b[96mAccuracy: 78.70005589105334\u001b[0m\n",
      "epoch: 5, loss: 470.6645147204399, total_correct: 58921 / 73357, --> \u001b[96mAccuracy: 80.32089643796775\u001b[0m\n",
      "epoch: 6, loss: 442.56205862760544, total_correct: 59768 / 73357, --> \u001b[96mAccuracy: 81.47552380822553\u001b[0m\n",
      "epoch: 7, loss: 420.70484405755997, total_correct: 60434 / 73357, --> \u001b[96mAccuracy: 82.38341262592527\u001b[0m\n",
      "epoch: 8, loss: 403.6817741394043, total_correct: 60937 / 73357, --> \u001b[96mAccuracy: 83.06910042668048\u001b[0m\n",
      "epoch: 9, loss: 388.4883622825146, total_correct: 61428 / 73357, --> \u001b[96mAccuracy: 83.73842987036002\u001b[0m\n",
      "Results for mnist: total correct: 52622 / 60000. \u001b[95mAccuracy: 87.70333333333333\u001b[0m\n",
      "Results for usps: total correct: 4775 / 7291. \u001b[95mAccuracy: 65.49170209847757\u001b[0m\n",
      "Results for svhn: total correct: 61784 / 73257. \u001b[95mAccuracy: 84.33869800838146\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 50 elementi da mnist per ogni classe. dirty: 73757\n",
      "epoch: 0, loss: 1389.220864057541, total_correct: 26106 / 73757, --> \u001b[96mAccuracy: 35.39460661360956\u001b[0m\n",
      "epoch: 1, loss: 848.0865434408188, total_correct: 46420 / 73757, --> \u001b[96mAccuracy: 62.93639925701967\u001b[0m\n",
      "epoch: 2, loss: 653.4463401436806, total_correct: 53397 / 73757, --> \u001b[96mAccuracy: 72.39584039480998\u001b[0m\n",
      "epoch: 3, loss: 560.9714864492416, total_correct: 56525 / 73757, --> \u001b[96mAccuracy: 76.6367937958431\u001b[0m\n",
      "epoch: 4, loss: 505.1237598359585, total_correct: 58299 / 73757, --> \u001b[96mAccuracy: 79.04198923492007\u001b[0m\n",
      "epoch: 5, loss: 467.6440255343914, total_correct: 59403 / 73757, --> \u001b[96mAccuracy: 80.53879631763765\u001b[0m\n",
      "epoch: 6, loss: 440.12150847911835, total_correct: 60202 / 73757, --> \u001b[96mAccuracy: 81.62208332768415\u001b[0m\n",
      "epoch: 7, loss: 419.9217168837786, total_correct: 60869 / 73757, --> \u001b[96mAccuracy: 82.52640427349269\u001b[0m\n",
      "epoch: 8, loss: 402.20863834023476, total_correct: 61340 / 73757, --> \u001b[96mAccuracy: 83.16498772997817\u001b[0m\n",
      "epoch: 9, loss: 386.99671533703804, total_correct: 61807 / 73757, --> \u001b[96mAccuracy: 83.79814797239584\u001b[0m\n",
      "Results for mnist: total correct: 55200 / 60000. \u001b[95mAccuracy: 92.0\u001b[0m\n",
      "Results for usps: total correct: 5244 / 7291. \u001b[95mAccuracy: 71.92429022082018\u001b[0m\n",
      "Results for svhn: total correct: 61857 / 73257. \u001b[95mAccuracy: 84.43834718866457\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 100 elementi da mnist per ogni classe. dirty: 74257\n",
      "epoch: 0, loss: 1313.3555796146393, total_correct: 29858 / 74257, --> \u001b[96mAccuracy: 40.20900386495549\u001b[0m\n",
      "epoch: 1, loss: 755.0500610470772, total_correct: 50426 / 74257, --> \u001b[96mAccuracy: 67.90740266910863\u001b[0m\n",
      "epoch: 2, loss: 569.9351171553135, total_correct: 56849 / 74257, --> \u001b[96mAccuracy: 76.5570922606623\u001b[0m\n",
      "epoch: 3, loss: 495.9684203863144, total_correct: 58984 / 74257, --> \u001b[96mAccuracy: 79.43224207818793\u001b[0m\n",
      "epoch: 4, loss: 452.04029473662376, total_correct: 60365 / 74257, --> \u001b[96mAccuracy: 81.29199940746327\u001b[0m\n",
      "epoch: 5, loss: 422.1378657221794, total_correct: 61265 / 74257, --> \u001b[96mAccuracy: 82.50400635630311\u001b[0m\n",
      "epoch: 6, loss: 398.5949704349041, total_correct: 62033 / 74257, --> \u001b[96mAccuracy: 83.53825228597978\u001b[0m\n",
      "epoch: 7, loss: 379.9995286911726, total_correct: 62550 / 74257, --> \u001b[96mAccuracy: 84.23448294436888\u001b[0m\n",
      "epoch: 8, loss: 364.1690269559622, total_correct: 63070 / 74257, --> \u001b[96mAccuracy: 84.93475362592079\u001b[0m\n",
      "epoch: 9, loss: 351.3092270195484, total_correct: 63446 / 74257, --> \u001b[96mAccuracy: 85.44110319565831\u001b[0m\n",
      "Results for mnist: total correct: 57197 / 60000. \u001b[95mAccuracy: 95.32833333333333\u001b[0m\n",
      "Results for usps: total correct: 5583 / 7291. \u001b[95mAccuracy: 76.57385818131944\u001b[0m\n",
      "Results for svhn: total correct: 62757 / 73257. \u001b[95mAccuracy: 85.66689872640157\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 500 elementi da mnist per ogni classe. dirty: 78257\n",
      "epoch: 0, loss: 1378.1989563703537, total_correct: 31106 / 78257, --> \u001b[96mAccuracy: 39.7485208990889\u001b[0m\n",
      "epoch: 1, loss: 834.3580809831619, total_correct: 51540 / 78257, --> \u001b[96mAccuracy: 65.85992307397422\u001b[0m\n",
      "epoch: 2, loss: 611.3973435461521, total_correct: 59401 / 78257, --> \u001b[96mAccuracy: 75.90503085985918\u001b[0m\n",
      "epoch: 3, loss: 513.0791360139847, total_correct: 62463 / 78257, --> \u001b[96mAccuracy: 79.81777987911624\u001b[0m\n",
      "epoch: 4, loss: 462.63524851202965, total_correct: 64059 / 78257, --> \u001b[96mAccuracy: 81.8572140511392\u001b[0m\n",
      "epoch: 5, loss: 429.27182748913765, total_correct: 65106 / 78257, --> \u001b[96mAccuracy: 83.19511353616929\u001b[0m\n",
      "epoch: 6, loss: 405.273270457983, total_correct: 65799 / 78257, --> \u001b[96mAccuracy: 84.08065732138978\u001b[0m\n",
      "epoch: 7, loss: 385.0027566552162, total_correct: 66416 / 78257, --> \u001b[96mAccuracy: 84.8690851936568\u001b[0m\n",
      "epoch: 8, loss: 368.8840342313051, total_correct: 66968 / 78257, --> \u001b[96mAccuracy: 85.57445340352939\u001b[0m\n",
      "epoch: 9, loss: 355.3743521720171, total_correct: 67363 / 78257, --> \u001b[96mAccuracy: 86.07920058269548\u001b[0m\n",
      "Results for mnist: total correct: 58813 / 60000. \u001b[95mAccuracy: 98.02166666666666\u001b[0m\n",
      "Results for usps: total correct: 5474 / 7291. \u001b[95mAccuracy: 75.0788643533123\u001b[0m\n",
      "Results for svhn: total correct: 63009 / 73257. \u001b[95mAccuracy: 86.01089315696794\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 1000 elementi da mnist per ogni classe. dirty: 83257\n",
      "epoch: 0, loss: 1339.4119319915771, total_correct: 37556 / 83257, --> \u001b[96mAccuracy: 45.108519403773855\u001b[0m\n",
      "epoch: 1, loss: 833.3003572821617, total_correct: 56536 / 83257, --> \u001b[96mAccuracy: 67.90540134763444\u001b[0m\n",
      "epoch: 2, loss: 624.1755912303925, total_correct: 63845 / 83257, --> \u001b[96mAccuracy: 76.684242766374\u001b[0m\n",
      "epoch: 3, loss: 521.7417590022087, total_correct: 67201 / 83257, --> \u001b[96mAccuracy: 80.71513506371836\u001b[0m\n",
      "epoch: 4, loss: 469.9056157171726, total_correct: 68874 / 83257, --> \u001b[96mAccuracy: 82.7245757113516\u001b[0m\n",
      "epoch: 5, loss: 433.54659658670425, total_correct: 70045 / 83257, --> \u001b[96mAccuracy: 84.13106405467407\u001b[0m\n",
      "epoch: 6, loss: 407.6072659790516, total_correct: 70764 / 83257, --> \u001b[96mAccuracy: 84.99465510407533\u001b[0m\n",
      "epoch: 7, loss: 387.5069819241762, total_correct: 71457 / 83257, --> \u001b[96mAccuracy: 85.82701754807404\u001b[0m\n",
      "epoch: 8, loss: 371.1672184318304, total_correct: 71893 / 83257, --> \u001b[96mAccuracy: 86.35069723867062\u001b[0m\n",
      "epoch: 9, loss: 357.28853572905064, total_correct: 72378 / 83257, --> \u001b[96mAccuracy: 86.93323083944894\u001b[0m\n",
      "Results for mnist: total correct: 59073 / 60000. \u001b[95mAccuracy: 98.455\u001b[0m\n",
      "Results for usps: total correct: 5821 / 7291. \u001b[95mAccuracy: 79.83815663146345\u001b[0m\n",
      "Results for svhn: total correct: 62976 / 73257. \u001b[95mAccuracy: 85.96584626725091\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 2000 elementi da mnist per ogni classe. dirty: 93257\n",
      "epoch: 0, loss: 1330.7983059883118, total_correct: 48028 / 93257, --> \u001b[96mAccuracy: 51.500691637088906\u001b[0m\n",
      "epoch: 1, loss: 828.5993303060532, total_correct: 66805 / 93257, --> \u001b[96mAccuracy: 71.63537321595162\u001b[0m\n",
      "epoch: 2, loss: 666.428940564394, total_correct: 72434 / 93257, --> \u001b[96mAccuracy: 77.67138123679723\u001b[0m\n",
      "epoch: 3, loss: 586.6894373595715, total_correct: 75130 / 93257, --> \u001b[96mAccuracy: 80.56231703786311\u001b[0m\n",
      "epoch: 4, loss: 533.3986813724041, total_correct: 76782 / 93257, --> \u001b[96mAccuracy: 82.33376582991089\u001b[0m\n",
      "epoch: 5, loss: 496.44782796502113, total_correct: 77935 / 93257, --> \u001b[96mAccuracy: 83.57013414542608\u001b[0m\n",
      "epoch: 6, loss: 467.2628770172596, total_correct: 78732 / 93257, --> \u001b[96mAccuracy: 84.42476168008835\u001b[0m\n",
      "epoch: 7, loss: 443.31604075431824, total_correct: 79589 / 93257, --> \u001b[96mAccuracy: 85.34372754860226\u001b[0m\n",
      "epoch: 8, loss: 423.98276545107365, total_correct: 80149 / 93257, --> \u001b[96mAccuracy: 85.94421866455065\u001b[0m\n",
      "epoch: 9, loss: 407.7850511074066, total_correct: 80648 / 93257, --> \u001b[96mAccuracy: 86.47929914108325\u001b[0m\n",
      "Results for mnist: total correct: 59314 / 60000. \u001b[95mAccuracy: 98.85666666666667\u001b[0m\n",
      "Results for usps: total correct: 5520 / 7291. \u001b[95mAccuracy: 75.70977917981072\u001b[0m\n",
      "Results for svhn: total correct: 61007 / 73257. \u001b[95mAccuracy: 83.27804851413518\u001b[0m\n",
      "    \n",
      "Sto rinfrescando la memoria con 5000 elementi da mnist per ogni classe. dirty: 123257\n",
      "epoch: 0, loss: 1365.1809776425362, total_correct: 75740 / 123257, --> \u001b[96mAccuracy: 61.44884266208004\u001b[0m\n",
      "epoch: 1, loss: 896.7720499038696, total_correct: 93406 / 123257, --> \u001b[96mAccuracy: 75.78149719691376\u001b[0m\n",
      "epoch: 2, loss: 728.2876097261906, total_correct: 99946 / 123257, --> \u001b[96mAccuracy: 81.08748387515516\u001b[0m\n",
      "epoch: 3, loss: 637.5508100092411, total_correct: 103118 / 123257, --> \u001b[96mAccuracy: 83.66096854539703\u001b[0m\n",
      "epoch: 4, loss: 582.9636876732111, total_correct: 104873 / 123257, --> \u001b[96mAccuracy: 85.08482276868656\u001b[0m\n",
      "epoch: 5, loss: 545.1667536050081, total_correct: 106235 / 123257, --> \u001b[96mAccuracy: 86.18983100351298\u001b[0m\n",
      "epoch: 6, loss: 516.4711851626635, total_correct: 107120 / 123257, --> \u001b[96mAccuracy: 86.90784296226583\u001b[0m\n",
      "epoch: 7, loss: 493.6847558617592, total_correct: 107891 / 123257, --> \u001b[96mAccuracy: 87.53336524497595\u001b[0m\n",
      "epoch: 8, loss: 474.8254106193781, total_correct: 108385 / 123257, --> \u001b[96mAccuracy: 87.93415384116116\u001b[0m\n",
      "epoch: 9, loss: 458.84221155941486, total_correct: 108935 / 123257, --> \u001b[96mAccuracy: 88.38037596241999\u001b[0m\n",
      "Results for mnist: total correct: 59799 / 60000. \u001b[95mAccuracy: 99.665\u001b[0m\n",
      "Results for usps: total correct: 5378 / 7291. \u001b[95mAccuracy: 73.76217254148952\u001b[0m\n",
      "Results for svhn: total correct: 59406 / 73257. \u001b[95mAccuracy: 81.09259183422745\u001b[0m\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "digits2 = split_dataset(joint)\n",
    "for N in (1,2,5,10,50,100,500,1000,2000,5000):\n",
    "    network2.load_state_dict(torch.load('PATHS/mnist_trained.pth'))\n",
    "    example_replay(N, digits2, network2, joint, svhn, joint_loader, svhn_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
